# Event Controller Dev Guide

The OpenShift Event Controller is a utility used as a service integrator for OpenShift and other third party components

## Setup Dev Environment

Before we can test locally, we need to install some dependencies and gather some information about our Cluster.

```
yum -y install libffi-devel
pip3 install requests pkiutils pyopenssl
```

Now, create a directory in which to store local configs. The directory name below coincides with the directory that would be mounted into a pod.

```
mkdir -p ./kubernetes.io/serviceaccount
oc login # Interactive step
oc whoami -t > kubernetes.io/serviceaccount/token
# Place OpenShift CA file at kubernetes.io/serviceaccount/ca.crt
echo QUIT | openssl s_client -showcerts -connect <kubernetes-master-hostname>:8443 2>&1  | openssl x509 -text | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' > kubernetes.io/serviceaccount/ca.crt
```

## Testing Source Locally


```
K8S_TOKEN=`oc whoami -t` K8S_API_ENDPOINT='master.example.com:8443' K8S_NAMESPACE=event-controller K8S_CA=./kubernetes.io/serviceaccount/ca.crt K8S_RESOURCE=routes python3 watch.py
```

You should see a log of data about the Namespace you passed in.

## Testing The Image Locally

```
docker run -v /home/esauer/src/oc-watcher-skel/kubernetes.io/:/etc/config:z -v /home/esauer/src/oc-watcher-skel/kubernetes.io/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount:z -e CONFIG_FILE=/etc/config/config.ini event-controller
```

If you want to debug the running image itself:

```
docker run -it --entrypoint=/bin/bash -v /path/to/kubernetes.io/conf:/etc/watcher/:z -v /path/tokubernetes.io/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount:z -e CONFIG_FILE=/etc/watcher/config.ini event-controller
```

## Configuration

The event controller can be configured via either Environment variables or an ini file. A sample config file can be found at `conf/config.ini.sample`. To run the watcher with a config file, run:

`python3 watch.py --config conf/config.ini`

## Plugin Architecture

The event controller is designed to be pluggable. New plugins can be created by simply creating a python module that implements a single `handle_event()` method, which takes a single `dict` object as an argument (the `event` object).

A plugin is invoked like so:

```python
  plugin = load_plugin(plugin_name)
  for k8s_event in getEvents():
    result,level = plugin.handle_event(self, k8s_event, self.config.getPluginConfig(), *args, **kwargs)
    log(result, level)
```

Let's look at a very simple plugin, called `plugin_simple`. This plugin is a single file init file loaded from a directory, `plugin_simple/__init__.py`:

```python
def handle_event(watcher, event, config):
    message = "Kind: {0}; Name: {1}".format(event['object']['kind'], event['object']['metadata']['name'])
    log_level = "INFO"
    return message, log_level
```

This plugin takes in the event object generated by the Kubernetes API, grabs a few choice fields, and creates a log message which is returned to the watcher.

From here, we can easily write plugins for the watcher that do things like:

- Create Alerts
- Integrate with Third party systems like DNS or PKI infrastructures

Happy Integrating!
